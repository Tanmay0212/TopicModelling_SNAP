{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author Tanmay\n",
    "\n",
    "import pandas as pd\n",
    "from gensim import corpora, models\n",
    "import gensim\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim.models import CoherenceModel\n",
    "import string\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Loading\n",
    "data = pd.read_csv('foodstamp_submissions_allyears.csv')\n",
    "\n",
    "#2 Preprocessing\n",
    "\n",
    "filtered_data = data[\n",
    "    ~data['selftext'].str.contains('\\[deleted\\]', case=False, na=False) &\n",
    "    ~data['selftext'].str.contains('\\[removed\\]', case=False, na=False)\n",
    "]\n",
    "\n",
    "# 3. Data Preprocessing\n",
    "# Handle NaN values and ensure the data type is string\n",
    "filtered_data['selftext'] = filtered_data['selftext'].fillna('')\n",
    "#Removing any links\n",
    "filtered_data['selftext'] = filtered_data['selftext'].str.replace(r'http\\S+', '', regex=True)\n",
    "# Remove punctuation, numbers, and special characters\n",
    "filtered_data['clean_selftext'] = filtered_data['selftext'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "filtered_data['clean_selftext'] = filtered_data['clean_selftext'].map(lambda x: re.sub('\\d+', '', x))\n",
    "# Convert to lowercase\n",
    "filtered_data['clean_selftext'] = filtered_data['clean_selftext'].map(lambda x: x.lower())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list from the dataframe as BERT expects list of docs as inputs\n",
    "docs = filtered_data['clean_selftext'].tolist()\n",
    "\n",
    "# Load English stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to remove stopwords from a document\n",
    "def remove_stopwords(text):\n",
    "    tokens = text.split()\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "    return filtered_text\n",
    "\n",
    "# Apply the function to your documents\n",
    "docs_no_stopwords = [remove_stopwords(doc) for doc in docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "# Create a BERTopic instance\n",
    "topic_model = BERTopic()\n",
    "\n",
    "# Fit the model and transform your documents into topics\n",
    "topics, probs = topic_model.fit_transform(docs_no_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('xmas', 1.635204719456826),\n",
       " ('gtgt', 1.635204719456826),\n",
       " ('election', 1.4782631603369536),\n",
       " ('cut', 0.9113165770548401),\n",
       " ('see', 0.7300504513342656),\n",
       " ('apply', 0.7280645569982707),\n",
       " ('one', 0.6404719649211392),\n",
       " ('', 1e-05),\n",
       " ('', 1e-05),\n",
       " ('', 1e-05)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get an overview of the topics\n",
    "topic_model.get_topic_info()\n",
    "\n",
    "# Retrieve individual topics\n",
    "#topic_model.get_topic(0)  # Replace 0 with the topic number you're interested in\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanmaybhardwaj/anaconda3/lib/python3.10/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1600: RuntimeWarning:\n",
      "\n",
      "k >= N for N * N square matrix. Attempting to use scipy.linalg.eigh instead.\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Visualize topics\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtopic_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisualize_topics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/bertopic/_bertopic.py:2240\u001b[0m, in \u001b[0;36mBERTopic.visualize_topics\u001b[0;34m(self, topics, top_n_topics, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m   2207\u001b[0m \u001b[39m\"\"\" Visualize topics, their sizes, and their corresponding words\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m \n\u001b[1;32m   2209\u001b[0m \u001b[39mThis visualization is highly inspired by LDAvis, a great visualization\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2237\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m   2238\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2239\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m-> 2240\u001b[0m \u001b[39mreturn\u001b[39;00m plotting\u001b[39m.\u001b[39;49mvisualize_topics(\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   2241\u001b[0m                                  topics\u001b[39m=\u001b[39;49mtopics,\n\u001b[1;32m   2242\u001b[0m                                  top_n_topics\u001b[39m=\u001b[39;49mtop_n_topics,\n\u001b[1;32m   2243\u001b[0m                                  custom_labels\u001b[39m=\u001b[39;49mcustom_labels,\n\u001b[1;32m   2244\u001b[0m                                  title\u001b[39m=\u001b[39;49mtitle,\n\u001b[1;32m   2245\u001b[0m                                  width\u001b[39m=\u001b[39;49mwidth,\n\u001b[1;32m   2246\u001b[0m                                  height\u001b[39m=\u001b[39;49mheight)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/bertopic/plotting/_topics.py:79\u001b[0m, in \u001b[0;36mvisualize_topics\u001b[0;34m(topic_model, topics, top_n_topics, custom_labels, title, width, height)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[39mif\u001b[39;00m topic_model\u001b[39m.\u001b[39mtopic_embeddings_ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     embeddings \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39mtopic_embeddings_[indices]\n\u001b[0;32m---> 79\u001b[0m     embeddings \u001b[39m=\u001b[39m UMAP(n_neighbors\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, n_components\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcosine\u001b[39;49m\u001b[39m'\u001b[39;49m, random_state\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m)\u001b[39m.\u001b[39;49mfit_transform(embeddings)\n\u001b[1;32m     80\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     embeddings \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39mc_tf_idf_\u001b[39m.\u001b[39mtoarray()[indices]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/umap/umap_.py:2887\u001b[0m, in \u001b[0;36mUMAP.fit_transform\u001b[0;34m(self, X, y, force_all_finite)\u001b[0m\n\u001b[1;32m   2851\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, force_all_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m   2852\u001b[0m     \u001b[39m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[1;32m   2853\u001b[0m \u001b[39m    output.\u001b[39;00m\n\u001b[1;32m   2854\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2885\u001b[0m \u001b[39m        Local radii of data points in the embedding (log-transformed).\u001b[39;00m\n\u001b[1;32m   2886\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2887\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, y, force_all_finite)\n\u001b[1;32m   2888\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2889\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dens:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/umap/umap_.py:2780\u001b[0m, in \u001b[0;36mUMAP.fit\u001b[0;34m(self, X, y, force_all_finite)\u001b[0m\n\u001b[1;32m   2776\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform_mode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   2777\u001b[0m     epochs \u001b[39m=\u001b[39m (\n\u001b[1;32m   2778\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epochs_list \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epochs_list \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epochs\n\u001b[1;32m   2779\u001b[0m     )\n\u001b[0;32m-> 2780\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membedding_, aux_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_embed_data(\n\u001b[1;32m   2781\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_raw_data[index],\n\u001b[1;32m   2782\u001b[0m         epochs,\n\u001b[1;32m   2783\u001b[0m         init,\n\u001b[1;32m   2784\u001b[0m         random_state,  \u001b[39m# JH why raw data?\u001b[39;49;00m\n\u001b[1;32m   2785\u001b[0m     )\n\u001b[1;32m   2787\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_epochs_list \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2788\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39membedding_list\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m aux_data:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/umap/umap_.py:2826\u001b[0m, in \u001b[0;36mUMAP._fit_embed_data\u001b[0;34m(self, X, n_epochs, init, random_state)\u001b[0m\n\u001b[1;32m   2822\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit_embed_data\u001b[39m(\u001b[39mself\u001b[39m, X, n_epochs, init, random_state):\n\u001b[1;32m   2823\u001b[0m     \u001b[39m\"\"\"A method wrapper for simplicial_set_embedding that can be\u001b[39;00m\n\u001b[1;32m   2824\u001b[0m \u001b[39m    replaced by subclasses.\u001b[39;00m\n\u001b[1;32m   2825\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2826\u001b[0m     \u001b[39mreturn\u001b[39;00m simplicial_set_embedding(\n\u001b[1;32m   2827\u001b[0m         X,\n\u001b[1;32m   2828\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraph_,\n\u001b[1;32m   2829\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_components,\n\u001b[1;32m   2830\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initial_alpha,\n\u001b[1;32m   2831\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_a,\n\u001b[1;32m   2832\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_b,\n\u001b[1;32m   2833\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepulsion_strength,\n\u001b[1;32m   2834\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnegative_sample_rate,\n\u001b[1;32m   2835\u001b[0m         n_epochs,\n\u001b[1;32m   2836\u001b[0m         init,\n\u001b[1;32m   2837\u001b[0m         random_state,\n\u001b[1;32m   2838\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_input_distance_func,\n\u001b[1;32m   2839\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metric_kwds,\n\u001b[1;32m   2840\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdensmap,\n\u001b[1;32m   2841\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_densmap_kwds,\n\u001b[1;32m   2842\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_dens,\n\u001b[1;32m   2843\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output_distance_func,\n\u001b[1;32m   2844\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_output_metric_kwds,\n\u001b[1;32m   2845\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moutput_metric \u001b[39min\u001b[39;49;00m (\u001b[39m\"\u001b[39;49m\u001b[39meuclidean\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39ml2\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   2846\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m   2847\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m   2848\u001b[0m         tqdm_kwds\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtqdm_kwds,\n\u001b[1;32m   2849\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/umap/umap_.py:1106\u001b[0m, in \u001b[0;36msimplicial_set_embedding\u001b[0;34m(data, graph, n_components, initial_alpha, a, b, gamma, negative_sample_rate, n_epochs, init, random_state, metric, metric_kwds, densmap, densmap_kwds, output_dens, output_metric, output_metric_kwds, euclidean_output, parallel, verbose, tqdm_kwds)\u001b[0m\n\u001b[1;32m   1102\u001b[0m     embedding \u001b[39m=\u001b[39m noisy_scale_coords(\n\u001b[1;32m   1103\u001b[0m         embedding, random_state, max_coord\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, noise\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m\n\u001b[1;32m   1104\u001b[0m     )\n\u001b[1;32m   1105\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(init, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m init \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mspectral\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1106\u001b[0m     embedding \u001b[39m=\u001b[39m spectral_layout(\n\u001b[1;32m   1107\u001b[0m         data,\n\u001b[1;32m   1108\u001b[0m         graph,\n\u001b[1;32m   1109\u001b[0m         n_components,\n\u001b[1;32m   1110\u001b[0m         random_state,\n\u001b[1;32m   1111\u001b[0m         metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m   1112\u001b[0m         metric_kwds\u001b[39m=\u001b[39;49mmetric_kwds,\n\u001b[1;32m   1113\u001b[0m     )\n\u001b[1;32m   1114\u001b[0m     \u001b[39m# We add a little noise to avoid local minima for optimization to come\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     embedding \u001b[39m=\u001b[39m noisy_scale_coords(\n\u001b[1;32m   1116\u001b[0m         embedding, random_state, max_coord\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, noise\u001b[39m=\u001b[39m\u001b[39m0.0001\u001b[39m\n\u001b[1;32m   1117\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/umap/spectral.py:304\u001b[0m, in \u001b[0;36mspectral_layout\u001b[0;34m(data, graph, dim, random_state, metric, metric_kwds, tol, maxiter)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspectral_layout\u001b[39m(\n\u001b[1;32m    264\u001b[0m     data,\n\u001b[1;32m    265\u001b[0m     graph,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m     maxiter\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    272\u001b[0m ):\n\u001b[1;32m    273\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[39m    Given a graph compute the spectral embedding of the graph. This is\u001b[39;00m\n\u001b[1;32m    275\u001b[0m \u001b[39m    simply the eigenvectors of the laplacian of the graph. Here we use the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[39m        The spectral embedding of the graph.\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m     \u001b[39mreturn\u001b[39;00m _spectral_layout(\n\u001b[1;32m    305\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    306\u001b[0m         graph\u001b[39m=\u001b[39;49mgraph,\n\u001b[1;32m    307\u001b[0m         dim\u001b[39m=\u001b[39;49mdim,\n\u001b[1;32m    308\u001b[0m         random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    309\u001b[0m         metric\u001b[39m=\u001b[39;49mmetric,\n\u001b[1;32m    310\u001b[0m         metric_kwds\u001b[39m=\u001b[39;49mmetric_kwds,\n\u001b[1;32m    311\u001b[0m         init\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mrandom\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    312\u001b[0m         tol\u001b[39m=\u001b[39;49mtol,\n\u001b[1;32m    313\u001b[0m         maxiter\u001b[39m=\u001b[39;49mmaxiter\n\u001b[1;32m    314\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/umap/spectral.py:521\u001b[0m, in \u001b[0;36m_spectral_layout\u001b[0;34m(data, graph, dim, random_state, metric, metric_kwds, init, method, tol, maxiter)\u001b[0m\n\u001b[1;32m    518\u001b[0m X[:, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m sqrt_deg \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(sqrt_deg)\n\u001b[1;32m    520\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39meigsh\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 521\u001b[0m     eigenvalues, eigenvectors \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49msparse\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49meigsh(\n\u001b[1;32m    522\u001b[0m         L,\n\u001b[1;32m    523\u001b[0m         k,\n\u001b[1;32m    524\u001b[0m         which\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSM\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    525\u001b[0m         ncv\u001b[39m=\u001b[39;49mnum_lanczos_vectors,\n\u001b[1;32m    526\u001b[0m         tol\u001b[39m=\u001b[39;49mtol \u001b[39mor\u001b[39;49;00m \u001b[39m1e-4\u001b[39;49m,\n\u001b[1;32m    527\u001b[0m         v0\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mones(L\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]),\n\u001b[1;32m    528\u001b[0m         maxiter\u001b[39m=\u001b[39;49mmaxiter \u001b[39mor\u001b[39;49;00m graph\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m] \u001b[39m*\u001b[39;49m \u001b[39m5\u001b[39;49m,\n\u001b[1;32m    529\u001b[0m     )\n\u001b[1;32m    530\u001b[0m \u001b[39melif\u001b[39;00m method \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlobpcg\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    531\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/scipy/sparse/linalg/_eigen/arpack/arpack.py:1605\u001b[0m, in \u001b[0;36meigsh\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, mode)\u001b[0m\n\u001b[1;32m   1600\u001b[0m warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mk >= N for N * N square matrix. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1601\u001b[0m               \u001b[39m\"\u001b[39m\u001b[39mAttempting to use scipy.linalg.eigh instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1602\u001b[0m               \u001b[39mRuntimeWarning\u001b[39;00m)\n\u001b[1;32m   1604\u001b[0m \u001b[39mif\u001b[39;00m issparse(A):\n\u001b[0;32m-> 1605\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot use scipy.linalg.eigh for sparse A with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1606\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mk >= N. Use scipy.linalg.eigh(A.toarray()) or\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1607\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m reduce k.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1608\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(A, LinearOperator):\n\u001b[1;32m   1609\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot use scipy.linalg.eigh for LinearOperator \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1610\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39mA with k >= N.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot use scipy.linalg.eigh for sparse A with k >= N. Use scipy.linalg.eigh(A.toarray()) or reduce k."
     ]
    }
   ],
   "source": [
    "# Visualize topics\n",
    "topic_model.visualize_topics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi im wondering can you be married and still g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_im_get_food_benefits</td>\n",
       "      <td>[im, get, food, benefits, month, income, card,...</td>\n",
       "      <td>[receiving food stamps california months (i th...</td>\n",
       "      <td>im - get - food - benefits - month - income - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not sure if this is only pa but i'm sure it co...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_im_get_food_benefits</td>\n",
       "      <td>[im, get, food, benefits, month, income, card,...</td>\n",
       "      <td>[receiving food stamps california months (i th...</td>\n",
       "      <td>im - get - food - benefits - month - income - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>today i was informed by my social worker that ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_im_get_food_benefits</td>\n",
       "      <td>[im, get, food, benefits, month, income, card,...</td>\n",
       "      <td>[receiving food stamps california months (i th...</td>\n",
       "      <td>im - get - food - benefits - month - income - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(i'm in alabama)\\n\\nso i filled out the online...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_im_get_food_benefits</td>\n",
       "      <td>[im, get, food, benefits, month, income, card,...</td>\n",
       "      <td>[receiving food stamps california months (i th...</td>\n",
       "      <td>im - get - food - benefits - month - income - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hello\\n\\ni am in new york\\n\\ni applied on apri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_im_get_food_benefits</td>\n",
       "      <td>[im, get, food, benefits, month, income, card,...</td>\n",
       "      <td>[receiving food stamps california months (i th...</td>\n",
       "      <td>im - get - food - benefits - month - income - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6337</th>\n",
       "      <td>i recently got approved for early learning coa...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_im_get_food_benefits</td>\n",
       "      <td>[im, get, food, benefits, month, income, card,...</td>\n",
       "      <td>[receiving food stamps california months (i th...</td>\n",
       "      <td>im - get - food - benefits - month - income - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>hello\\n\\ni really hate to bother asking here b...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_im_get_food_benefits</td>\n",
       "      <td>[im, get, food, benefits, month, income, card,...</td>\n",
       "      <td>[receiving food stamps california months (i th...</td>\n",
       "      <td>im - get - food - benefits - month - income - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339</th>\n",
       "      <td>a friend of mine receives ssi payments for her...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_im_get_food_benefits</td>\n",
       "      <td>[im, get, food, benefits, month, income, card,...</td>\n",
       "      <td>[receiving food stamps california months (i th...</td>\n",
       "      <td>im - get - food - benefits - month - income - ...</td>\n",
       "      <td>0.936643</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6340</th>\n",
       "      <td>i looked outside my door and there was a card ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_im_get_food_benefits</td>\n",
       "      <td>[im, get, food, benefits, month, income, card,...</td>\n",
       "      <td>[receiving food stamps california months (i th...</td>\n",
       "      <td>im - get - food - benefits - month - income - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6341</th>\n",
       "      <td>i don't know how to ask this question so i'm h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0_im_get_food_benefits</td>\n",
       "      <td>[im, get, food, benefits, month, income, card,...</td>\n",
       "      <td>[receiving food stamps california months (i th...</td>\n",
       "      <td>im - get - food - benefits - month - income - ...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6342 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Document  Topic  \\\n",
       "0     hi im wondering can you be married and still g...      0   \n",
       "1     not sure if this is only pa but i'm sure it co...      0   \n",
       "2     today i was informed by my social worker that ...      0   \n",
       "3     (i'm in alabama)\\n\\nso i filled out the online...      0   \n",
       "4     hello\\n\\ni am in new york\\n\\ni applied on apri...      0   \n",
       "...                                                 ...    ...   \n",
       "6337  i recently got approved for early learning coa...      0   \n",
       "6338  hello\\n\\ni really hate to bother asking here b...      0   \n",
       "6339  a friend of mine receives ssi payments for her...      0   \n",
       "6340  i looked outside my door and there was a card ...      0   \n",
       "6341  i don't know how to ask this question so i'm h...      0   \n",
       "\n",
       "                        Name  \\\n",
       "0     0_im_get_food_benefits   \n",
       "1     0_im_get_food_benefits   \n",
       "2     0_im_get_food_benefits   \n",
       "3     0_im_get_food_benefits   \n",
       "4     0_im_get_food_benefits   \n",
       "...                      ...   \n",
       "6337  0_im_get_food_benefits   \n",
       "6338  0_im_get_food_benefits   \n",
       "6339  0_im_get_food_benefits   \n",
       "6340  0_im_get_food_benefits   \n",
       "6341  0_im_get_food_benefits   \n",
       "\n",
       "                                         Representation  \\\n",
       "0     [im, get, food, benefits, month, income, card,...   \n",
       "1     [im, get, food, benefits, month, income, card,...   \n",
       "2     [im, get, food, benefits, month, income, card,...   \n",
       "3     [im, get, food, benefits, month, income, card,...   \n",
       "4     [im, get, food, benefits, month, income, card,...   \n",
       "...                                                 ...   \n",
       "6337  [im, get, food, benefits, month, income, card,...   \n",
       "6338  [im, get, food, benefits, month, income, card,...   \n",
       "6339  [im, get, food, benefits, month, income, card,...   \n",
       "6340  [im, get, food, benefits, month, income, card,...   \n",
       "6341  [im, get, food, benefits, month, income, card,...   \n",
       "\n",
       "                                    Representative_Docs  \\\n",
       "0     [receiving food stamps california months (i th...   \n",
       "1     [receiving food stamps california months (i th...   \n",
       "2     [receiving food stamps california months (i th...   \n",
       "3     [receiving food stamps california months (i th...   \n",
       "4     [receiving food stamps california months (i th...   \n",
       "...                                                 ...   \n",
       "6337  [receiving food stamps california months (i th...   \n",
       "6338  [receiving food stamps california months (i th...   \n",
       "6339  [receiving food stamps california months (i th...   \n",
       "6340  [receiving food stamps california months (i th...   \n",
       "6341  [receiving food stamps california months (i th...   \n",
       "\n",
       "                                            Top_n_words  Probability  \\\n",
       "0     im - get - food - benefits - month - income - ...     1.000000   \n",
       "1     im - get - food - benefits - month - income - ...     1.000000   \n",
       "2     im - get - food - benefits - month - income - ...     1.000000   \n",
       "3     im - get - food - benefits - month - income - ...     1.000000   \n",
       "4     im - get - food - benefits - month - income - ...     1.000000   \n",
       "...                                                 ...          ...   \n",
       "6337  im - get - food - benefits - month - income - ...     1.000000   \n",
       "6338  im - get - food - benefits - month - income - ...     1.000000   \n",
       "6339  im - get - food - benefits - month - income - ...     0.936643   \n",
       "6340  im - get - food - benefits - month - income - ...     1.000000   \n",
       "6341  im - get - food - benefits - month - income - ...     1.000000   \n",
       "\n",
       "      Representative_document  \n",
       "0                       False  \n",
       "1                       False  \n",
       "2                       False  \n",
       "3                       False  \n",
       "4                       False  \n",
       "...                       ...  \n",
       "6337                    False  \n",
       "6338                    False  \n",
       "6339                    False  \n",
       "6340                    False  \n",
       "6341                    False  \n",
       "\n",
       "[6342 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_document_info(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1eb14c017a40174f1cd2873120226af2c3765f9e1b4e1a76ddbb97d090fc061c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
